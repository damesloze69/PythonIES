{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bb42861-8832-459c-bd4b-2f71ef55de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime as dt\n",
    "from pandas.tseries.frequencies import to_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99fde26a-7603-4bc1-9136-69bcc33c8268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date       High        Low       Open      Close     Volume  \\\n",
      "0  2017-11-13  77.000000  74.309998  74.690002  75.400002  2892600.0   \n",
      "1  2017-11-14  75.480003  74.449997  75.099998  75.400002  1863300.0   \n",
      "2  2017-11-15  77.660004  74.599998  75.320000  77.529999  2731000.0   \n",
      "3  2017-11-16  80.709999  77.410004  77.720001  80.309998  2986800.0   \n",
      "4  2017-11-17  80.029999  77.580002  79.650002  78.839996  2196700.0   \n",
      "\n",
      "   Adj Close  \n",
      "0  69.163460  \n",
      "1  69.163460  \n",
      "2  71.117287  \n",
      "3  73.667343  \n",
      "4  72.662735  \n",
      "         Date       High        Low       Open      Close   Volume  Adj Close\n",
      "0  2017-11-13  42.209999  41.020000  41.259998  42.180000  2033400  42.180000\n",
      "1  2017-11-14  42.230000  41.419998  41.970001  42.180000  1738700  42.180000\n",
      "2  2017-11-15  42.820000  41.770000  42.000000  42.639999  2462000  42.639999\n",
      "3  2017-11-16  43.349998  42.810001  42.970001  42.990002  1918500  42.990002\n",
      "4  2017-11-17  43.160000  42.610001  42.650002  42.779999  1578800  42.779999\n",
      "         Date       High        Low       Open      Close     Volume  \\\n",
      "0  2017-11-13  40.570000  39.549999  39.680000  39.650002  4681300.0   \n",
      "1  2017-11-14  39.660000  38.169998  39.389999  38.230000  4205900.0   \n",
      "2  2017-11-15  38.070000  37.380001  37.849998  37.910000  4694600.0   \n",
      "3  2017-11-16  38.340000  37.709999  37.930000  38.160000  4645600.0   \n",
      "4  2017-11-17  38.959999  38.310001  38.419998  38.680000  3254100.0   \n",
      "\n",
      "   Adj Close  \n",
      "0  34.829708  \n",
      "1  33.582333  \n",
      "2  33.301243  \n",
      "3  33.520851  \n",
      "4  33.977623  \n"
     ]
    }
   ],
   "source": [
    "ABC = pd.read_csv('ABC.csv', sep=',')\n",
    "print(ABC.head())\n",
    "CBRE = pd.read_csv('CBRE.csv', sep=',')\n",
    "print(CBRE.head())\n",
    "DVN = pd.read_csv('DVN.csv', sep=',')\n",
    "print(DVN.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f51d5c-e6f1-436c-9184-2e37fe2257f7",
   "metadata": {},
   "source": [
    "1. Is there a company that has no difference between the Close and Adj Close columns?\n",
    "What does it mean from the financial point of view for the stock (you can get bonus\n",
    "partial points)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac945bd1-c16a-4759-a8a6-faf14bf560e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABC['Close'].equals(ABC['Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0555566-7768-4e7b-abca-825955dee6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBRE['Close'].equals(CBRE['Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d12d633-c66f-45ba-9b3c-c607f56ca8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DVN['Close'].equals(DVN['Adj Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5625f-73e9-4705-8b5a-5c5943aa6ff5",
   "metadata": {},
   "source": [
    "Yes, CBRE company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019a3fc-92af-4971-a214-23c5cce2753d",
   "metadata": {},
   "source": [
    "2. What is the highest and lowest price (Adj Close) each company recorded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf8fbc6-f0ae-425a-8678-11200f224c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Adjusted Close price for company ABC is: 164.20936584472656\n",
      "Lowest Adjusted Close price for company ABC is: 66.3444595336914\n"
     ]
    }
   ],
   "source": [
    "ABC_highest = ABC['Adj Close'].max()\n",
    "print('Highest Adjusted Close price for company ABC is:', ABC_highest)\n",
    "ABC_lowest = ABC['Adj Close'].min()\n",
    "print('Lowest Adjusted Close price for company ABC is:', ABC_lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fab7ca7-3487-425d-940a-876d0a3d9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Adjusted Close price for company CBRE is: 110.3000030517578\n",
      "Lowest Adjusted Close price for company CBRE is: 29.82999992370605\n"
     ]
    }
   ],
   "source": [
    "CBRE_highest = CBRE['Adj Close'].max()\n",
    "print('Highest Adjusted Close price for company CBRE is:', CBRE_highest)\n",
    "CBRE_lowest = CBRE['Adj Close'].min()\n",
    "print('Lowest Adjusted Close price for company CBRE is:', CBRE_lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492a187c-67f9-4b49-bc74-51cc9a04b9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Adjusted Close price for company DVN is: 78.04000091552734\n",
      "Lowest Adjusted Close price for company DVN is: 4.919719219207764\n"
     ]
    }
   ],
   "source": [
    "DVN_highest = DVN['Adj Close'].max()\n",
    "print('Highest Adjusted Close price for company DVN is:', DVN_highest)\n",
    "DVN_lowest = DVN['Adj Close'].min()\n",
    "print('Lowest Adjusted Close price for company DVN is:', DVN_lowest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1188f2-e2bf-40ad-8d35-f163b3435cc7",
   "metadata": {},
   "source": [
    "(1pt task) Calculate logarithmic returns from Adj Close. For each company report on\n",
    "its, min, man, mean, median of the return distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2674172-2cf2-40ab-8288-d82ca4e3b796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistive of a returns of ABC company are as follows: count    1258.000000\n",
      "mean        0.000631\n",
      "std         0.019003\n",
      "min        -0.111552\n",
      "25%        -0.009673\n",
      "50%         0.001383\n",
      "75%         0.011062\n",
      "max         0.111677\n",
      "Name: Adj Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ABC_log_returns = np.log(ABC['Adj Close']/ABC['Adj Close'].shift(1))\n",
    "ABC_describe_returns = ABC_log_returns.describe()\n",
    "print('Descriptive statistive of a returns of ABC company are as follows:', ABC_describe_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2457d0f9-9c15-44ec-8fc9-a56d3e5cbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistive of a returns of CBRE company are as follows: count    1258.000000\n",
      "mean        0.000497\n",
      "std         0.023281\n",
      "min        -0.188811\n",
      "25%        -0.009041\n",
      "50%         0.000896\n",
      "75%         0.011069\n",
      "max         0.155321\n",
      "Name: Adj Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "CBRE_log_returns = np.log(CBRE['Adj Close']/CBRE['Adj Close'].shift(1))\n",
    "CBRE_describe_returns = CBRE_log_returns.describe()\n",
    "print('Descriptive statistive of a returns of CBRE company are as follows:', CBRE_describe_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d105b6c-88cd-47c2-92e8-c66eaf0a173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistive of a returns of DVN company are as follows: count    1258.000000\n",
      "mean        0.000575\n",
      "std         0.038790\n",
      "min        -0.468360\n",
      "25%        -0.019178\n",
      "50%         0.000770\n",
      "75%         0.019624\n",
      "max         0.191216\n",
      "Name: Adj Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "DVN_log_returns = np.log(DVN['Adj Close']/DVN['Adj Close'].shift(1))\n",
    "DVN_describe_returns = DVN_log_returns.describe()\n",
    "print('Descriptive statistive of a returns of DVN company are as follows:', DVN_describe_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b3b7f-fd65-45e7-8b89-810e253f6a67",
   "metadata": {},
   "source": [
    "When did each company record the highest gain and highest loss for the day?\n",
    "(logarithmic loss). Hint: idxmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c36be77c-0cd3-4ce8-9b1f-2a35e3865b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC company had the highest gain on 585    2020-03-13\n",
      "Name: Date, dtype: object and lowest on 586    2020-03-16\n",
      "Name: Date, dtype: object .\n",
      "CBRE company had the highest gain on 745    2020-10-29\n",
      "Name: Date, dtype: object and lowest on 586    2020-03-16\n",
      "Name: Date, dtype: object .\n",
      "DVN company had the highest gain on 589    2020-03-19\n",
      "Name: Date, dtype: object and lowest on 581    2020-03-09\n",
      "Name: Date, dtype: object .\n"
     ]
    }
   ],
   "source": [
    "ABC['Log Returns'] = ABC_log_returns\n",
    "CBRE['Log Returns'] = CBRE_log_returns\n",
    "DVN['Log Returns'] = DVN_log_returns\n",
    "\n",
    "ABC_highest = ABC[ABC['Log Returns'] == ABC['Log Returns'].max()]\n",
    "ABC_lowest = ABC[ABC['Log Returns'] == ABC['Log Returns'].min()]\n",
    "\n",
    "CBRE_highest = CBRE[CBRE['Log Returns'] == CBRE['Log Returns'].max()]\n",
    "CBRE_lowest = CBRE[CBRE['Log Returns'] == CBRE['Log Returns'].min()]\n",
    "\n",
    "DVN_highest = DVN[DVN['Log Returns'] == DVN['Log Returns'].max()]\n",
    "DVN_lowest = DVN[DVN['Log Returns'] == DVN['Log Returns'].min()]\n",
    "\n",
    "print('ABC company had the highest gain on', ABC_highest['Date'], 'and lowest on', ABC_lowest['Date'],'.')\n",
    "print('CBRE company had the highest gain on', CBRE_highest['Date'], 'and lowest on', CBRE_lowest['Date'],'.')\n",
    "print('DVN company had the highest gain on', DVN_highest['Date'], 'and lowest on', DVN_lowest['Date'],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc8561d9-989c-4311-94ae-d7cdc6f2b900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC company volumes:                       Volume\n",
      "Year Week_Number            \n",
      "2017 46           12670400.0\n",
      "     47            5915700.0\n",
      "     48           10108500.0\n",
      "     49            9060600.0\n",
      "     50           11209500.0\n",
      "...                      ...\n",
      "2022 41            5764400.0\n",
      "     42            4783900.0\n",
      "     43            4998900.0\n",
      "     44            7863400.0\n",
      "     45           18943000.0\n",
      "\n",
      "[261 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkohoutova001\\AppData\\Local\\Temp\\ipykernel_9292\\3577498627.py:4: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  ABC['Week_Number'] = ABC['Date'].dt.week\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m CBRE \u001b[38;5;241m=\u001b[39m CBRE[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Getting week number\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m CBRE[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeek_Number\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mCBRE\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39mweek\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Getting year. Weeknum is common across years to we need to create unique index by using year and weeknum\u001b[39;00m\n\u001b[0;32m     19\u001b[0m CBRE[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m CBRE[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:512\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 512\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "ABC = ABC[['Date', 'Volume']]\n",
    "\n",
    "# Getting week number\n",
    "ABC['Week_Number'] = ABC['Date'].dt.week\n",
    "\n",
    "# Getting year. Weeknum is common across years to we need to create unique index by using year and weeknum\n",
    "ABC['Year'] = ABC['Date'].dt.year\n",
    "\n",
    "# Grouping based on required values\n",
    "ABC_volume = ABC.groupby(['Year','Week_Number']).agg({'Volume':'sum'})\n",
    "print('ABC company volumes:', ABC_volume)\n",
    "\n",
    "CBRE = CBRE[['Date', 'Volume']]\n",
    "\n",
    "# Getting week number\n",
    "CBRE['Week_Number'] = CBRE['Date'].dt.week\n",
    "\n",
    "# Getting year. Weeknum is common across years to we need to create unique index by using year and weeknum\n",
    "CBRE['Year'] = CBRE['Date'].dt.year\n",
    "\n",
    "# Grouping based on required values\n",
    "CBRE_volume = CBRE.groupby(['Year','Week_Number']).agg({'Volume':'sum'})\n",
    "print('CBRE company volumes:', CBRE_volume)\n",
    "\n",
    "DVN = DVN[['Date', 'Volume']]\n",
    "\n",
    "# Getting week number\n",
    "DVN['Week_Number'] = DVN['Date'].dt.week\n",
    "\n",
    "# Getting year. Weeknum is common across years to we need to create unique index by using year and weeknum\n",
    "DVN['Year'] = DVN['Date'].dt.year\n",
    "\n",
    "# Grouping based on required values\n",
    "DVN_volume = DVN.groupby(['Year','Week_Number']).agg({'Volume':'sum'})\n",
    "print('DVN company volumes:', DVN_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebe8409f-8b4f-44c3-8d40-a32ac313611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC['Date'] = pd.to_datetime(ABC['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289f75f-b74b-412d-85e6-83d43789d97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
