{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bb42861-8832-459c-bd4b-2f71ef55de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime as dt\n",
    "from pandas.tseries.frequencies import to_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99fde26a-7603-4bc1-9136-69bcc33c8268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date       High        Low       Open      Close     Volume  \\\n",
      "0  2017-11-13  77.000000  74.309998  74.690002  75.400002  2892600.0   \n",
      "1  2017-11-14  75.480003  74.449997  75.099998  75.400002  1863300.0   \n",
      "2  2017-11-15  77.660004  74.599998  75.320000  77.529999  2731000.0   \n",
      "3  2017-11-16  80.709999  77.410004  77.720001  80.309998  2986800.0   \n",
      "4  2017-11-17  80.029999  77.580002  79.650002  78.839996  2196700.0   \n",
      "\n",
      "   Adj Close  \n",
      "0  69.163460  \n",
      "1  69.163460  \n",
      "2  71.117287  \n",
      "3  73.667343  \n",
      "4  72.662735  \n",
      "         Date       High        Low       Open      Close   Volume  Adj Close\n",
      "0  2017-11-13  42.209999  41.020000  41.259998  42.180000  2033400  42.180000\n",
      "1  2017-11-14  42.230000  41.419998  41.970001  42.180000  1738700  42.180000\n",
      "2  2017-11-15  42.820000  41.770000  42.000000  42.639999  2462000  42.639999\n",
      "3  2017-11-16  43.349998  42.810001  42.970001  42.990002  1918500  42.990002\n",
      "4  2017-11-17  43.160000  42.610001  42.650002  42.779999  1578800  42.779999\n",
      "         Date       High        Low       Open      Close     Volume  \\\n",
      "0  2017-11-13  40.570000  39.549999  39.680000  39.650002  4681300.0   \n",
      "1  2017-11-14  39.660000  38.169998  39.389999  38.230000  4205900.0   \n",
      "2  2017-11-15  38.070000  37.380001  37.849998  37.910000  4694600.0   \n",
      "3  2017-11-16  38.340000  37.709999  37.930000  38.160000  4645600.0   \n",
      "4  2017-11-17  38.959999  38.310001  38.419998  38.680000  3254100.0   \n",
      "\n",
      "   Adj Close  \n",
      "0  34.829708  \n",
      "1  33.582333  \n",
      "2  33.301243  \n",
      "3  33.520851  \n",
      "4  33.977623  \n"
     ]
    }
   ],
   "source": [
    "ABC = pd.read_csv('ABC.csv', sep=',')\n",
    "print(ABC.head())\n",
    "CBRE = pd.read_csv('CBRE.csv', sep=',')\n",
    "print(CBRE.head())\n",
    "DVN = pd.read_csv('DVN.csv', sep=',')\n",
    "print(DVN.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f51d5c-e6f1-436c-9184-2e37fe2257f7",
   "metadata": {},
   "source": [
    "1. Is there a company that has no difference between the Close and Adj Close columns?\n",
    "What does it mean from the financial point of view for the stock (you can get bonus\n",
    "partial points)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac945bd1-c16a-4759-a8a6-faf14bf560e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABC['Close'].equals(ABC['Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0555566-7768-4e7b-abca-825955dee6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBRE['Close'].equals(CBRE['Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d12d633-c66f-45ba-9b3c-c607f56ca8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DVN['Close'].equals(DVN['Adj Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5625f-73e9-4705-8b5a-5c5943aa6ff5",
   "metadata": {},
   "source": [
    "Yes, CBRE company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019a3fc-92af-4971-a214-23c5cce2753d",
   "metadata": {},
   "source": [
    "2. What is the highest and lowest price (Adj Close) each company recorded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf8fbc6-f0ae-425a-8678-11200f224c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Adjusted Close price for company ABC is: 164.20936584472656\n",
      "Lowest Adjusted Close price for company ABC is: 66.3444595336914\n"
     ]
    }
   ],
   "source": [
    "ABC_highest = ABC['Adj Close'].max()\n",
    "print('Highest Adjusted Close price for company ABC is:', ABC_highest)\n",
    "ABC_lowest = ABC['Adj Close'].min()\n",
    "print('Lowest Adjusted Close price for company ABC is:', ABC_lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fab7ca7-3487-425d-940a-876d0a3d9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Adjusted Close price for company CBRE is: 110.3000030517578\n",
      "Lowest Adjusted Close price for company CBRE is: 29.82999992370605\n"
     ]
    }
   ],
   "source": [
    "CBRE_highest = CBRE['Adj Close'].max()\n",
    "print('Highest Adjusted Close price for company CBRE is:', CBRE_highest)\n",
    "CBRE_lowest = CBRE['Adj Close'].min()\n",
    "print('Lowest Adjusted Close price for company CBRE is:', CBRE_lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492a187c-67f9-4b49-bc74-51cc9a04b9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Adjusted Close price for company DVN is: 78.04000091552734\n",
      "Lowest Adjusted Close price for company DVN is: 4.919719219207764\n"
     ]
    }
   ],
   "source": [
    "DVN_highest = DVN['Adj Close'].max()\n",
    "print('Highest Adjusted Close price for company DVN is:', DVN_highest)\n",
    "DVN_lowest = DVN['Adj Close'].min()\n",
    "print('Lowest Adjusted Close price for company DVN is:', DVN_lowest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1188f2-e2bf-40ad-8d35-f163b3435cc7",
   "metadata": {},
   "source": [
    "(1pt task) Calculate logarithmic returns from Adj Close. For each company report on\n",
    "its, min, man, mean, median of the return distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2674172-2cf2-40ab-8288-d82ca4e3b796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistive of a returns of ABC company are as follows: count    1258.000000\n",
      "mean        0.000631\n",
      "std         0.019003\n",
      "min        -0.111552\n",
      "25%        -0.009673\n",
      "50%         0.001383\n",
      "75%         0.011062\n",
      "max         0.111677\n",
      "Name: Adj Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ABC_log_returns = np.log(ABC['Adj Close']/ABC['Adj Close'].shift(1))\n",
    "ABC_describe_returns = ABC_log_returns.describe()\n",
    "print('Descriptive statistive of a returns of ABC company are as follows:', ABC_describe_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2457d0f9-9c15-44ec-8fc9-a56d3e5cbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistive of a returns of CBRE company are as follows: count    1258.000000\n",
      "mean        0.000497\n",
      "std         0.023281\n",
      "min        -0.188811\n",
      "25%        -0.009041\n",
      "50%         0.000896\n",
      "75%         0.011069\n",
      "max         0.155321\n",
      "Name: Adj Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "CBRE_log_returns = np.log(CBRE['Adj Close']/CBRE['Adj Close'].shift(1))\n",
    "CBRE_describe_returns = CBRE_log_returns.describe()\n",
    "print('Descriptive statistive of a returns of CBRE company are as follows:', CBRE_describe_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d105b6c-88cd-47c2-92e8-c66eaf0a173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistive of a returns of DVN company are as follows: count    1258.000000\n",
      "mean        0.000575\n",
      "std         0.038790\n",
      "min        -0.468360\n",
      "25%        -0.019178\n",
      "50%         0.000770\n",
      "75%         0.019624\n",
      "max         0.191216\n",
      "Name: Adj Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "DVN_log_returns = np.log(DVN['Adj Close']/DVN['Adj Close'].shift(1))\n",
    "DVN_describe_returns = DVN_log_returns.describe()\n",
    "print('Descriptive statistive of a returns of DVN company are as follows:', DVN_describe_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b3b7f-fd65-45e7-8b89-810e253f6a67",
   "metadata": {},
   "source": [
    "When did each company record the highest gain and highest loss for the day?\n",
    "(logarithmic loss). Hint: idxmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c36be77c-0cd3-4ce8-9b1f-2a35e3865b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC company had the highest gain on 585    2020-03-13\n",
      "Name: Date, dtype: object and lowest on 586    2020-03-16\n",
      "Name: Date, dtype: object .\n",
      "CBRE company had the highest gain on 745    2020-10-29\n",
      "Name: Date, dtype: object and lowest on 586    2020-03-16\n",
      "Name: Date, dtype: object .\n",
      "DVN company had the highest gain on 589    2020-03-19\n",
      "Name: Date, dtype: object and lowest on 581    2020-03-09\n",
      "Name: Date, dtype: object .\n"
     ]
    }
   ],
   "source": [
    "ABC['Log Returns'] = ABC_log_returns\n",
    "CBRE['Log Returns'] = CBRE_log_returns\n",
    "DVN['Log Returns'] = DVN_log_returns\n",
    "\n",
    "ABC_highest = ABC[ABC['Log Returns'] == ABC['Log Returns'].max()]\n",
    "ABC_lowest = ABC[ABC['Log Returns'] == ABC['Log Returns'].min()]\n",
    "\n",
    "CBRE_highest = CBRE[CBRE['Log Returns'] == CBRE['Log Returns'].max()]\n",
    "CBRE_lowest = CBRE[CBRE['Log Returns'] == CBRE['Log Returns'].min()]\n",
    "\n",
    "DVN_highest = DVN[DVN['Log Returns'] == DVN['Log Returns'].max()]\n",
    "DVN_lowest = DVN[DVN['Log Returns'] == DVN['Log Returns'].min()]\n",
    "\n",
    "print('ABC company had the highest gain on', ABC_highest['Date'], 'and lowest on', ABC_lowest['Date'],'.')\n",
    "print('CBRE company had the highest gain on', CBRE_highest['Date'], 'and lowest on', CBRE_lowest['Date'],'.')\n",
    "print('DVN company had the highest gain on', DVN_highest['Date'], 'and lowest on', DVN_lowest['Date'],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc8561d9-989c-4311-94ae-d7cdc6f2b900",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m ABC \u001b[38;5;241m=\u001b[39m ABC[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      3\u001b[0m logic \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m----> 5\u001b[0m ABC \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_clipboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m ABC\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(logic)\n\u001b[0;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m to_offset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6D\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\io\\clipboards.py:88\u001b[0m, in \u001b[0;36mread_clipboard\u001b[1;34m(sep, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sep) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     83\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_clipboard with regex separator does not work properly with c engine.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     85\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m     86\u001b[0m     )\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m read_csv(StringIO(text), sep\u001b[38;5;241m=\u001b[39msep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:155\u001b[0m, in \u001b[0;36mPythonParser.__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_col_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_col_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)))\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_date_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m no_thousands_columns: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_dates:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\dataprocessing\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:217\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[1;34m(self, columns)\u001b[0m\n\u001b[0;32m    207\u001b[0m missing_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    209\u001b[0m         {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     )\n\u001b[0;32m    215\u001b[0m )\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[1;32m--> 217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column provided to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_dates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    222\u001b[0m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[0;32m    224\u001b[0m ]\n",
      "\u001b[1;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'Date'"
     ]
    }
   ],
   "source": [
    "df = pd.concat([ABC, CBRE, DVN], keys=['ABC','CBRE','DVN'], axis=1)\n",
    "ABC = ABC[['Date', 'Volume']]\n",
    "logic = {'Volume': 'sum'}\n",
    "\n",
    "ABC = pd.read_clipboard(parse_dates=['Date'], index_col=['Date'])\n",
    "ABC.resample('W').apply(logic)\n",
    "df.index -= to_offset(\"6D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebe8409f-8b4f-44c3-8d40-a32ac313611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC['Date'] = pd.to_datetime(ABC['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289f75f-b74b-412d-85e6-83d43789d97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
